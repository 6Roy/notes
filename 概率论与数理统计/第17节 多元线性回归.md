# 多远线性回归

## 1 多元线性回归的数学描述

### 定义：多元线性回归
* 声明
$$
随机变量与，p个普通变量x_1,\cdots,x_p
$$
* 多元线性回归表示
$$
\begin{cases}
    y=\beta_0+\beta_1x_1+\cdots+\beta_px_p+\varepsilon\\
    E(\varepsilon)=0,Var(\varepsilon)=\sigma^2<+\infin
\end{cases}
$$
* 样本方程组表示(矩阵向量)

$$
Y=X\beta+\varepsilon\\
E(\varepsilon)=0,Var(\varepsilon)=\sigma^2I_n\\
Y=\begin{bmatrix}
    y_1\\
    \vdots\\
    y_n
\end{bmatrix},
X=\begin{bmatrix}
    1 &x_{11} &\cdots &x_{1p}\\
    \vdots &\vdots &&\vdots\\
    1&x_{n1}&\cdots&x_{np}
\end{bmatrix},
\beta=\begin{bmatrix}
    \beta_0\\
    \vdots\\
    \beta_p
\end{bmatrix},
\varepsilon=\begin{bmatrix}
    \varepsilon_1\\
    \vdots\\
    \varepsilon_n
\end{bmatrix},
$$

* 假设检验与参数估计中的表示
$$
Y=X\beta+\varepsilon\\
\varepsilon\sim N(0,\sigma^2I_n)\\
$$


## 2 参数估计与统计性质
### 最小二乘法
* 残差平方和
$$
Q(\beta)=(Y-X\beta)^T(Y-X\beta)
$$
* 偏导数引理
$$
\frac{\partial(a^Tx)}{\partial x}=\frac{\partial (x^Ta)}{\partial x}=a\\
\frac{\partial(x^TAx)}{\partial x}=2Ax
$$
* 求得参数
$$
\hat{\beta}=(X^TX)^{-1}X^TY
$$
* p元线性回归方程为
$$
\hat{y}=\hat{\beta}_0+\hat{\beta}_1x_1+\cdots+\hat{\beta}_px_p
$$
### 定理：矩阵的数字特征
* $E(Ax)=AE(x)$
* $Var(Ax)=AVar(x)A^T,Cov(Ax,By)=ACov(x,y)B^T$

### 定理：矩阵的迹
* $tr(A)=\sum a_{ij}$
* $tr(A+B)=tr(A)+tr(B)$
* $tr(AB)=tr(BA)$
* $若A^2=A是对称幂等阵，则tr(A)=rank(A)$

### 定理：系数\beta性质
* $E(\hat{\beta})=\beta,Var(\hat{\beta})=\sigma^2(X^TX)^{-1}$
* 协方差矩阵最小
* $\hat{\beta}$是方差最小的线性无偏估计

### 定理：残差向量e与残差平方和Q的性质

* $E(e)=0,Var(e)=\sigma^2[I_n-X(X^TX)^{-1}X^T], Cov(e,\hat{\beta})=0$
* $E(Q)=(n-p-1)\sigma^2$

### 定理：相互独立

$$
Z_1=A\varepsilon+c,Z_2=B\varepsilon+d\\
Z_1,Z_2相互独立的充要条件是AB^T=0
$$

### 定理：多元线性回归的性质

* $\hat{\beta}\sim N(\beta,\sigma^2(X^TX)^{-1}$
* $e\sim N(0,\sigma^2[I_n-X(X^TX)^{-1}X^T])$
* $\hat{\beta},e相互独立,\hat{\beta},Q相互独立$
* $\frac{Q}{\sigma^2}\sim \chi^2(n-p-1)$
## 3 显著性检验

### 定义：假设之间没有关系

$$
H_0:\beta_1=\cdots=\beta_p=0,H_1：\beta_1,\cdots,\beta_p不全为零
$$

### 显著性检验
使用$\frac{U}{Q}$的比值作为检验统计量，进行假设检验。
$$
L_{yy}=Q+U
$$

检验统计量
$$
F=\frac{\frac{U}{\sigma^2}/p}{\frac{Q}{\sigma^2}/(n-p-1)}=\frac{n-p-1}{p}\frac{U}{Q}\sim F(p,n-p-1)
$$
计算拒绝域
$$
W=\{F:F\geq F_{1-\alpha}(p,n-p-1)\}
$$
## 4 单个回归系数的显著性检验与区间估计
### 单回归系数的显著性检验
假设
$$
H_{0i}:\beta_i=0,H_{1i}:\beta_i\not = 0
$$
检验统计量
$$
t_i=\frac{\hat{\beta}_i-\beta_i}{\hat(\sigma)\sqrt{c_{ii}}}\sim t(n-p-1)
$$
确定拒绝域
$$
W_i=\{t_i:|t_i|\geq t_{1-\frac{\alpha}{2}}(n-p-1)\}
$$

### 单回归系数的区间估计
置信水平为1-\alpha的置信区间如下
$$
[\hat{\beta}_i-\hat{\sigma}t_{1-\frac{\alpha}{2}}(n-p-1)\sqrt{c_{ii}},\hat{\beta}_i+\hat{\sigma}t_{1-\frac{\alpha}{2}}(n-p-1)\sqrt{c_{ii}}]
$$
## 5 预测控制

> 未涉及内容：  
> #可化为线性回归的曲线回归  
> #自变量选择与“最优”回归方程选择  
> #异常情况的诊断处理  


状态转移方程

$$
f[n][m]=max\{f[n-1][m-k]+pmf[n][k],0<k<m\} 
$$
$$
f[n][m]=\begin{cases}
pmf[1][m] & n=1 \\
max\{f[n-1][m-k]+pmf[n][k]\} & n>1,0<k<m
    
\end{cases}

$$

$$
f[i][j]=\begin{cases}
    f[i][j]=0 & i=j \\
    D[i][j]+min{f[i][k]+f[k][j]}&i\leq k<j
\end{cases}
$$

$$
\sum_{k=2}^n\sum_{i=2}^{n-k}\sum_{j=i+1}^{i-1}n*i*j=O(n^3)
$$